import streamlit as st
import tensorflow as tf
from PIL import Image
import numpy as np

# 1. Page Configuration
st.set_page_config(page_title="AI vs Human Image Detector", page_icon="üîç", layout="centered")

# 2. Optimized Model Loading (TFLite)
@st.cache_resource
def load_tflite_model(model_path):
    # Interpreter is the TFLite version of "model"
    interpreter = tf.lite.Interpreter(model_path=model_path)
    interpreter.allocate_tensors()
    return interpreter

# Load your quantized model (Ensure this file is in your GitHub repo)
try:
    interpreter = load_tflite_model('model_quantized.tflite')
    input_details = interpreter.get_input_details()
    output_details = interpreter.get_output_details()
except Exception as e:
    st.error(f"Model file not found! Please upload 'model_quantized.tflite' to your repository.")
    st.stop()

# 3. App Header & Styling
st.title("üîç AI vs Human Image Detector")
st.markdown("""
Upload any image to see if it was generated by an **AI** or taken by a **Human**.
*Model optimized with **Float16 Quantization** for faster web deployment.*
""")

# 4. Image Upload Logic
uploaded_file = st.file_uploader("Choose an image...", type=["jpg", "jpeg", "png"])

if uploaded_file is not None:
    # Display the uploaded image
    img = Image.open(uploaded_file)
    st.image(img, caption="Uploaded Image", use_container_width=True)
    
    # 5. Preprocessing
    # Resize to 32x32 for CIFAKE architecture
    img_resized = img.resize((32, 32))
    img_array = tf.keras.preprocessing.image.img_to_array(img_resized)
    img_array = np.expand_dims(img_array, axis=0).astype(np.float32) 

    # 6. Prediction Logic
    if st.button("Run Detection"):
        with st.spinner('Analyzing pixel patterns...'):
            # --- TFLite Inference Steps ---
            # Step 1: Set the input tensor
            interpreter.set_tensor(input_details[0]['index'], img_array)
            
            # Step 2: Run the model
            interpreter.invoke()
            
            # Step 3: Get the result from the output tensor
            prediction = interpreter.get_tensor(output_details[0]['index'])[0][0]
            
            # --- Result Display ---
            # Class 0 = AI Generated (Fake) | Class 1 = Human Photograph (Real)
            if prediction < 0.5:
                confidence = (1 - prediction) 
                st.error(f"### Result: AI GENERATED")
                st.write(f"Confidence Score: **{confidence * 100:.2f}%**")
                st.progress(float(confidence))
            else:
                confidence = prediction 
                st.success(f"### Result: HUMAN PHOTOGRAPH")
                st.write(f"Confidence Score: **{confidence * 100:.2f}%**")
                st.progress(float(confidence))

# Footer
st.divider()
st.caption("Developed for BCA Final Year Project - 2026 | Powered by TensorFlow Lite")